{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T12:24:42.305518Z",
     "start_time": "2025-05-07T12:24:39.981968Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import random\n",
    "import src.generate_encodings as ge\n",
    "import src.prediction_models as pm\n",
    "import src.predictor_optimizer as pop\n",
    "from copy import copy\n",
    "import warnings\n",
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fadc630185b18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T12:24:42.800385Z",
     "start_time": "2025-05-07T12:24:42.798710Z"
    }
   },
   "outputs": [],
   "source": [
    "debugging = False\n",
    "demo_case = True\n",
    "update_params_after_each_cycle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee68673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T09:43:42.500363147Z",
     "start_time": "2025-05-05T13:24:45.034001Z"
    }
   },
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "\n",
    "class HiddenWarnings():\n",
    "    def __enter__(self):\n",
    "        # Save the current filter settings before changing them\n",
    "        self._previous_filters = warnings.filters[:]\n",
    "        # Ignore all warnings\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        # Restore the original warning filter settings\n",
    "        warnings.filters = self._previous_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"defining Parameters for Input_Data\"\"\"\n",
    "\n",
    "#sequence params\n",
    "dataset = \"D7PM05\"\n",
    "activity_threshold = 1 #Threshold for considering a mutants score as active or inactive for all datasets (data hab been preprocessed) \n",
    "repr_type = \"blosum80\"\n",
    "\n",
    "\n",
    "\"\"\"Defining further ModelParameter\"\"\"\n",
    "\n",
    "#mlde params\n",
    "n_top = 0.95 #Percentage cutoff of top scoring datapoints, targeted to be identified during the MLDE Cycles\n",
    "n_samples = 10  # realistic range: [5,10,20,100]\n",
    "n_starting_points = 1000  #realistic, up to 200 points to be expected as common practice\n",
    "highest_starting_fraction = 0.40  # Range from the lowest scoring datapoint to allowed percentage within sorted datapoints, allowed as starting points for MLDE Benchmark. Default: Median (0.5)\n",
    "n_cycles = 100\n",
    "\n",
    "#model params\n",
    "model_type = \"svr\"  # xgboost, rf, lightgbm, adaboost, svr, linear, ridge, lasso\n",
    "cv_folds = 5\n",
    "early_stopping_fraction = 0.1\n",
    "\n",
    "#hypertuning params\n",
    "initial_trials = 500 if model_type not in [\"linear\", \"ridge\",\n",
    "                                           \"lasso\"] else 10000  #trials per group to optimize the parameters for the mlde model - at the very beginning before the benchmark.\n",
    "n_trials = 200  # trials per group to optimize the parameters for the mlde model - after each cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c1338",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T09:43:42.514761059Z",
     "start_time": "2025-05-05T13:24:45.086390Z"
    }
   },
   "outputs": [],
   "source": [
    "#prepare Dataset and Embeddings\n",
    "\n",
    "if repr_type not in [\"esmc_600m\", \"esmc300m\"]:\n",
    "    import_data = f\"../Data/Protein_Gym_Datasets/{dataset}.csv\"\n",
    "    ids = []\n",
    "    sequences = []\n",
    "    scores = []\n",
    "\n",
    "    with open(import_data, \"r\") as infile:\n",
    "        for i, line in enumerate(infile.readlines()[1:]):\n",
    "            line = line[:-1].split(\",\")\n",
    "            id = line[0]\n",
    "            sequence = line[1]\n",
    "            label = line[4]\n",
    "            ids.append(id)\n",
    "            sequences.append(sequence)\n",
    "            scores.append(label)\n",
    "            if i == 0:\n",
    "                wildtype_seq = line[6]\n",
    "    data = [(id, \n",
    "             sequence, \n",
    "             ge.generate_sequence_encodings(repr_type, [sequence])[0], \n",
    "             round(float(label), 3)) for id, sequence, label in zip(ids, sequences, scores)]\n",
    "\n",
    "else: #load referring ESM Embeddings\n",
    "    print(\"Loading ESM Embeddings not implemented yet.\")\n",
    "\n",
    "data = sorted(data, key=lambda isxy: isxy[3])\n",
    "print(\"Applied Data-Set:\", dataset)\n",
    "print(\"Number of datapoints:\", len(data))\n",
    "print(\"Wildtype Sequence:\", wildtype_seq)\n",
    "print(\"maximum score:\", max([isxy[3] for isxy in data]))\n",
    "print(\"minimum score:\", min([isxy[3] for isxy in data]))\n",
    "print(\"Representation Type:\", repr_type)\n",
    "print(\"Activity Threshold:\", activity_threshold)\n",
    "print(\"Maximum Starting Score:\", round(max([isxy[3] for isxy in data]) * highest_starting_fraction, 3))\n",
    "print(\"Data has been loaded and encoded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5c1e10e30e94c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T09:43:42.517631879Z",
     "start_time": "2025-05-05T13:25:04.290632Z"
    }
   },
   "outputs": [],
   "source": [
    "#Performance evaluation\n",
    "\n",
    "def pearson_correlation(x, y):\n",
    "    if len(x) != len(y):\n",
    "        raise ValueError(\"Lists x and y must have the same length.\")\n",
    "    n = len(x)\n",
    "    sum_x = sum(x)\n",
    "    sum_y = sum(y)\n",
    "    sum_xy = sum(xi * yi for xi, yi in zip(x, y))\n",
    "    sum_x2 = sum(xi ** 2 for xi in x)\n",
    "    sum_y2 = sum(yi ** 2 for yi in y)\n",
    "\n",
    "    numerator = n * sum_xy - sum_x * sum_y\n",
    "    denominator = ((n * sum_x2 - sum_x ** 2) * (n * sum_y2 - sum_y ** 2)) ** 0.5\n",
    "\n",
    "    if denominator == 0:\n",
    "        raise ValueError(\"Denominator is zero, correlation undefined.\")\n",
    "    return numerator / denominator\n",
    "\n",
    "def spearman_correlation(x, y):\n",
    "    if len(x) != len(y):\n",
    "        raise ValueError(\"Lists x and y must have the same length.\")\n",
    "    def rank(data):\n",
    "        # Assign ranks, average in case of ties\n",
    "        sorted_data = sorted((val, idx) for idx, val in enumerate(data))\n",
    "        ranks = [0] * len(data)\n",
    "        i = 0\n",
    "        while i < len(data):\n",
    "            val, idx = sorted_data[i]\n",
    "            j = i\n",
    "            while j < len(data) and sorted_data[j][0] == val:\n",
    "                j += 1\n",
    "            avg_rank = (i + j - 1) / 2 + 1  # ranks start from 1\n",
    "            for k in range(i, j):\n",
    "                ranks[sorted_data[k][1]] = avg_rank\n",
    "            i = j\n",
    "        return ranks\n",
    "  \n",
    "    rank_x = rank(x)\n",
    "    rank_y = rank(y)\n",
    "\n",
    "    return pearson_correlation(rank_x, rank_y)\n",
    "\n",
    "\n",
    "def r2(y_trues: list, y_preds: list) -> float:\n",
    "    true_mean = np.mean([float(y) for y in y_trues])\n",
    "    rss = sum((float(y_true) - float(y_pred)) ** 2 for y_true, y_pred in zip(y_preds, y_trues))\n",
    "    tss = sum([(float(y_pred) - float(true_mean)) ** 2 for y_pred in y_preds])\n",
    "    EPSILON = float(1 ** -9)\n",
    "\n",
    "    return 1 - (rss / (tss + EPSILON)) if tss == 0 else 1 - (rss / tss)\n",
    "\n",
    "\n",
    "def rmse(y_trues: list, y_preds: list) -> float:\n",
    "    n = len(y_preds)\n",
    "    EPSILON = float(1 ** -9)\n",
    "    mse = sum((float(y_true) - float(y_pred)) ** 2 for y_true, y_pred in zip(y_preds, y_trues)) / n\n",
    "    return sqrt(mse + EPSILON) if mse == 0 else sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3fcbafa83f4d50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T09:43:42.519780287Z",
     "start_time": "2025-05-05T13:25:04.345261Z"
    }
   },
   "outputs": [],
   "source": [
    "#Function to display chosen datapoints\n",
    "\n",
    "# Assuming y_mlde, remaining_data, data, and data_set_name_shortened are already defined\n",
    "\n",
    "def display_datapoints_distribution(y_mlde, remaining_data, iteration: int = None, show_in_browser: bool = False):\n",
    "    min_score = round(float(min([float(isxy[3]) for isxy in data])), 3)\n",
    "    max_score = round(float(max([float(isxy[3]) for isxy in data])), 3)\n",
    "\n",
    "    n_bins = 100\n",
    "    plotwidth = 1000\n",
    "\n",
    "    binned_mlde_scores = dict()\n",
    "    binned_remaining_data = dict()\n",
    "\n",
    "    bin_edges = np.linspace(min_score, max_score, n_bins)\n",
    "\n",
    "    def bin_value(y, bin_edges):\n",
    "        lower = float(10 ** -9)\n",
    "        upper = float(10 ** 9)\n",
    "        y = float(y)\n",
    "        for i in bin_edges:\n",
    "            if i < y:\n",
    "                lower = float(i)\n",
    "            else:\n",
    "                upper = float(i)\n",
    "                break\n",
    "        return lower if abs(y - lower) < abs(y - upper) else upper\n",
    "\n",
    "    # First loop for y_mlde\n",
    "    for y in y_mlde:\n",
    "        binned = bin_value(y, bin_edges)\n",
    "        binned_mlde_scores[binned] = binned_mlde_scores.get(binned, 0) + 1\n",
    "\n",
    "    # Second loop for remaining_data\n",
    "    for isxy in remaining_data:\n",
    "        y = isxy[3]\n",
    "        binned = bin_value(y, bin_edges)\n",
    "        binned_remaining_data[binned] = binned_remaining_data.get(binned, 0) + 1\n",
    "\n",
    "    # Create ONE subplot only\n",
    "    scoring_plt = make_subplots(rows=1, cols=1)\n",
    "\n",
    "    # Add grey bars first (background)\n",
    "    scoring_plt.add_trace(\n",
    "        go.Bar(\n",
    "            name=\"Remaining-Data-Points\",\n",
    "            x=list(binned_remaining_data.keys()),\n",
    "            y=list(binned_remaining_data.values()),\n",
    "            marker=dict(color=\"grey\")\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Add red bars on top (foreground)\n",
    "    scoring_plt.add_trace(\n",
    "        go.Bar(\n",
    "            name=f\"MLDE-Starting-Points ({sum(binned_mlde_scores.values())} Points)\",\n",
    "            x=list(binned_mlde_scores.keys()),\n",
    "            y=list(binned_mlde_scores.values()),\n",
    "            marker=dict(color=\"red\")\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    if iteration != None:\n",
    "        title = f\"Known vs To-Discover-Datapoints from {dataset}-Dataset used within {iteration}. MLDE Cycle\"\n",
    "    else:\n",
    "        title = f\"Known vs To-Discover-Datapoints from {dataset}-Dataset used within MLDE Cycle\"\n",
    "\n",
    "    scoring_plt.update_layout(\n",
    "        title_text=title,\n",
    "        title_font=dict(color=\"black\", size=20),\n",
    "        showlegend=True,\n",
    "        barmode='overlay',  # Important for overlapping bars\n",
    "        paper_bgcolor='rgb(233,233,233)',\n",
    "        plot_bgcolor='rgb(233,233,233)',\n",
    "        width=plotwidth,\n",
    "        legend=dict(\n",
    "            font=dict(color=\"black\", size=12)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    scoring_plt.update_yaxes(\n",
    "        dict(\n",
    "            type=\"log\",\n",
    "            title_text=\"Number of sequences\",\n",
    "            title_font=dict(color=\"black\"),\n",
    "            color='black',\n",
    "            showgrid=True,\n",
    "            gridcolor='grey',\n",
    "            griddash=\"dot\",\n",
    "            gridwidth=0.1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    scoring_plt.update_xaxes(\n",
    "        dict(\n",
    "            title_text=\"Binned Activity Score of sequence\",\n",
    "            title_font=dict(color=\"black\"),\n",
    "            range=[min_score, max_score],\n",
    "            color='black',\n",
    "            showgrid=True,\n",
    "            gridcolor='grey',\n",
    "            griddash=\"dot\",\n",
    "            gridwidth=0.1\n",
    "        )\n",
    "    )\n",
    "    import plotly.io as pio\n",
    "    if show_in_browser:\n",
    "        pio.renderers.default = \"browser\"\n",
    "    else:\n",
    "        pio.renderers.default = \"notebook_connected\"\n",
    "    scoring_plt.show()\n",
    "    return scoring_plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544fea9b0567c31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T09:43:42.520152278Z",
     "start_time": "2025-05-05T13:31:49.583664Z"
    }
   },
   "outputs": [],
   "source": [
    "#Preparing Datapoints for Benchmark\n",
    "\n",
    "min_starting_fraction = 0.2 #quote of maximum inactive samples within all MLDE samples\n",
    "counter = 0\n",
    "\n",
    "#check whether MLDE Starting Criteria have been chosen wisely\n",
    "\n",
    "max_starting_score = round(max([isxy[3] for isxy in data]) * highest_starting_fraction, 3)\n",
    "\n",
    "print(f\"Highest possible Activity Score within initial MLDE Startingset: {max_starting_score}\")\n",
    "if max_starting_score < activity_threshold:\n",
    "    warnings.warn(\"The highest starting Datapoint is still in the range of inactive classified sequences. The to be trained model will perform poorly\")\n",
    "else:\n",
    "    print(\"The highest possible starting Datapoint exceeds the range of inactive classified sequences.\\n\"\n",
    "          \"The MLDE model will benefit herefrom.\")\n",
    "          \n",
    "try:\n",
    "    potential_starting_points = [isxy for isxy in data if isxy[3] <= max_starting_score]\n",
    "    min_starting_points = random.sample([isxy for isxy in data if isxy[3] == min(isxy[3] for isxy in potential_starting_points)]\n",
    "                                       round(n_starting_points * min_starting_fraction))\n",
    "    remaining_starting_points = random.sample([isxy for isxy in potential_starting_points if isxy not in min_starting_points],n_starting_points - len(min_starting_points))                            \n",
    "except:\n",
    "    raise ValueError(\n",
    "        \"Amount of available, allowed Amount of Active or Inactive Starting Points does not meet Criteria of max_quote_of_inactives and highest_starting_fraction!\")\n",
    "\n",
    "mlde_datapoints = min_starting_points + remaining_starting_points\n",
    "\n",
    "sequences_mlde = [isxy[1] for isxy in mlde_datapoints]\n",
    "x_mlde = [isxy[2] for isxy in mlde_datapoints]\n",
    "y_mlde = [isxy[3] for isxy in mlde_datapoints]\n",
    "print(\"Declared MLDE Starting-Points and remaining dataset\")\n",
    "remaining_data = [isxy for isxy in data if isxy not in mlde_datapoints]\n",
    "random.shuffle(remaining_data)\n",
    "\n",
    "top_mutants = [isxy[0] for isxy in sorted(remaining_data, key=lambda isxy: isxy[3], reverse=True) if isxy[3] >= activity_threshold][:n_top]\n",
    "top_x = [isxy[1] for isxy in sorted(remaining_data, key=lambda isxy: isxy[2], reverse=True)[:n_top]]\n",
    "top_y = [isxy[2] for isxy in sorted(remaining_data, key=lambda isxy: isxy[2], reverse=True)[:n_top]]\n",
    "# print([round(float(y),2) for y in top_y])\n",
    "with HiddenWarnings():\n",
    "    with HiddenPrints():\n",
    "        display_datapoints_distribution(y_mlde=y_mlde, remaining_data=remaining_data, show_in_browser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184f4d9cb608a026",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T09:43:42.520371846Z",
     "start_time": "2025-05-05T13:31:56.993372Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Create a suitable hyperparameter-set for the initial MLDE-Model\"\"\"\n",
    "if not demo_case:\n",
    "    mlde_optimizer = pop.Sequential_Optimizer(model_type=model_type, cv_folds=cv_folds, x_arr=x_mlde, y_arr=y_mlde,\n",
    "                                              initial_params={},\n",
    "                                              trials_per_group=initial_trials,\n",
    "                                              early_stopping_fraction=early_stopping_fraction,\n",
    "                                              n_jobs=1)\n",
    "\n",
    "    mlde_optimizer.optimize_stepwise()\n",
    "    best_trial = mlde_optimizer.get_best_trial()\n",
    "    mlde_params = mlde_optimizer.get_best_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1731aed4df8f9b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T09:43:42.520556228Z",
     "start_time": "2025-05-05T13:31:58.341954Z"
    }
   },
   "outputs": [],
   "source": [
    "mlde_params_xgboost = {'subsample': 0.4919977609964233, 'colsample_bytree': 0.44409804279321397, 'max_depth': 82,\n",
    "                       'min_child_weight': 0.2037190569366557, 'reg_alpha': 3.1708589729977215,\n",
    "                       'reg_lambda': 6.826403977807785}\n",
    "\n",
    "mlde_params_lightgbm = {'min_data_in_leaf': 5, 'num_leaves': 15, 'min_data_in_bin': 1,\n",
    "                        'feature_fraction': 0.2721281361692248, 'learning_rate': 0.2999956879962157, 'max_bin': 35,\n",
    "                        'n_estimators': 287, 'bagging_fraction': 0.5763358085600521}\n",
    "\n",
    "if demo_case:\n",
    "    mlde_params = mlde_params_xgboost if model_type == \"xgboost\" else mlde_params_lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865a84f0135e387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T09:43:42.524190836Z",
     "start_time": "2025-05-05T13:31:59.975068Z"
    }
   },
   "outputs": [],
   "source": [
    "finished = False\n",
    "print(\n",
    "    f\"starting the MLDE-Benchmark with {n_cycles} cycles, starting at {n_starting_points} sequences. Discovery of {n_samples} per Cycle to identify the top {n_top} sequences from list.\"\n",
    ")\n",
    "print()\n",
    "\n",
    "results = []  # save each iterations highest achieved sequence score and the average over all sequences and standard deviation\n",
    "val_performances = []  # track each iterations R2 and RMSE Performance\n",
    "test_performances = []\n",
    "\n",
    "previous_R2 = -999\n",
    "current_R2 = -999\n",
    "best_R2 = float(current_R2)\n",
    "\n",
    "for i in range(n_cycles):\n",
    "    print(f\"########################## Starting Cycle {i + 1}/{n_cycles} ##########################\")\n",
    "    print()\n",
    "    counter = 1\n",
    "    if i > 0:\n",
    "        print(\"Training a more effective MLDE predictor for the next iteration\")\n",
    "\n",
    "    best_cycle_R2 = None\n",
    "    best_cycle_model = None\n",
    "    training_successful = True\n",
    "\n",
    "    while not float(current_R2) > float(previous_R2):\n",
    "        mlde_model = pm.ActivityPredictor(model_type=model_type,\n",
    "                                          x_arr=x_mlde,\n",
    "                                          y_arr=y_mlde,\n",
    "                                          shuffle_data=True,\n",
    "                                          early_stopping=10,\n",
    "                                          params=mlde_params)\n",
    "        with HiddenPrints():\n",
    "            with HiddenWarnings():\n",
    "                mlde_model.train(k_folds=cv_folds)\n",
    "                current_R2 = mlde_model.get_performance()[0]\n",
    "        counter += 1\n",
    "\n",
    "        if best_cycle_R2 is None or current_R2 > best_cycle_R2:\n",
    "            best_cycle_R2 = copy(current_R2)\n",
    "            best_cycle_model = copy(mlde_model)\n",
    "\n",
    "        if counter >= 5000:\n",
    "            mlde_model = best_cycle_model\n",
    "            training_successful = False\n",
    "            break\n",
    "\n",
    "    val_R2 = round(mlde_model.get_performance()[0],3)\n",
    "    val_RMSE = round(mlde_model.get_performance()[0],3)\n",
    "\n",
    "    if training_successful:\n",
    "        print(\n",
    "            f\"Cycle No {i + 1}/{n_cycles}: Model Performance after {counter} training attempts: \"\n",
    "            f\"{val_R2}, {val_RMSE}\")\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            f\"Current Model Performance does not exceed the last iterations model  after {counter} iterations of Training.\"\n",
    "            f\" Therefore training has been stopped and the best attempt is now used for prediction.\")\n",
    "\n",
    "    list_predictions = []\n",
    "    with tqdm(total=len(remaining_data), desc=\"Predicting all remaining datapoints within the dataset...\") as pbar:\n",
    "        with HiddenPrints():\n",
    "            with HiddenWarnings():\n",
    "                for sxy in remaining_data:\n",
    "                    list_predictions.append(mlde_model.predict([sxy[1]])[0])\n",
    "                    pbar.update(1)\n",
    "            # list_predictions = mlde_model.predict([sxy[1] for sxy in remaining_data])\n",
    "\n",
    "    r2_test = round(r2([(sxy[2]) for sxy in remaining_data], list_predictions),3)\n",
    "    rmse_test = round(rmse([sxy[2] for sxy in remaining_data], list_predictions),3)\n",
    "\n",
    "    print(f\"Model Performance on all Datapoints: {r2_test}, {rmse_test}\")\n",
    "    test_performances.append((r2_test, rmse_test))\n",
    "\n",
    "    top_predictions = sorted(\n",
    "        [sxy for sxy in zip([sxy[0] for sxy in remaining_data], [sxy[1] for sxy in remaining_data], list_predictions)],\n",
    "        key=lambda sxy: sxy[2], reverse=True)[:n_samples]\n",
    "\n",
    "    #else:\n",
    "    print(f\"Top {n_samples} predicted sequences' pred scores: {[round(sxy[2], 2) for sxy in top_predictions]}\")\n",
    "\n",
    "    top_predictions_y_trues = []\n",
    "    for sxy_top in top_predictions:\n",
    "        for sxy_remaining in remaining_data:\n",
    "            if sxy_top[0] == sxy_remaining[0]:\n",
    "                #present a list of y_trues for the top predictions in comparison\n",
    "                top_predictions_y_trues.append(sxy_remaining[2])\n",
    "\n",
    "                #update mlde trainingpoints-range\n",
    "                x_mlde.append(sxy_top[1])\n",
    "                y_mlde.append(sxy_remaining[2])\n",
    "\n",
    "    mlde_data = [(x, y) for x, y in zip(x_mlde, y_mlde)]\n",
    "    random.shuffle(mlde_data)\n",
    "    x_mlde = [xy[0] for xy in mlde_data]\n",
    "    y_mlde = [xy[1] for xy in mlde_data]\n",
    "\n",
    "    for top_prediction in top_predictions_y_trues:\n",
    "        if top_prediction in top_y:\n",
    "            print(f\"Found one of the top {n_top} sequence during Cycle {i + 1}.\")\n",
    "            finished = True\n",
    "\n",
    "    highest_score = max(top_predictions_y_trues)\n",
    "    mean_score = round((sum(top_predictions_y_trues) / n_samples), 3)\n",
    "    standard_dev = round(sqrt(sum([(y - mean_score) ** 2 for y in top_predictions_y_trues]) / n_samples), 3)\n",
    "    results.append((i + 1, highest_score, mean_score, standard_dev))\n",
    "\n",
    "    if finished:\n",
    "        break\n",
    "\n",
    "    print(\n",
    "        f\"Top {n_samples} predicted sequences' true scores: {[round(y_true, 2) for y_true in top_predictions_y_trues]}\")\n",
    "    print()\n",
    "\n",
    "    #update remaining data\n",
    "    remaining_data = [sxy for sxy in remaining_data if sxy[0] not in [sxy[0] for sxy in top_predictions]]\n",
    "    random.shuffle(remaining_data)\n",
    "\n",
    "    #update last iterations previous_R2\n",
    "    previous_R2 = current_R2\n",
    "\n",
    "    #optinal: udpate params\n",
    "    if update_params_after_each_cycle:\n",
    "        print(\"Updating MLDE Parameters...\")\n",
    "        mlde_optimizer = pop.Sequential_Optimizer(model_type=model_type, cv_folds=cv_folds, x_arr=x_mlde, y_arr=y_mlde,\n",
    "                                                  initial_params=copy(mlde_params),\n",
    "                                                  trials_per_group=int(n_trials),\n",
    "                                                  early_stopping_fraction=early_stopping_fraction,\n",
    "                                                  n_jobs=1)\n",
    "\n",
    "        with HiddenPrints():\n",
    "            mlde_optimizer.optimize_stepwise()\n",
    "            best_trial = mlde_optimizer.get_best_trial()\n",
    "        if mlde_params != mlde_optimizer.get_best_params():\n",
    "            mlde_params = mlde_optimizer.get_best_params()  # might even overwrite with the same params\n",
    "            print(\"Hyperparameters updated.\")\n",
    "        else:\n",
    "            print(\"Current Hyperparameters maintained.\")\n",
    "\n",
    "    print()\n",
    "\n",
    "print(\n",
    "    f\"MLDE-Performance-Ranking finished after {i + 1}/{n_trials} trials {\"successfully\" if finished else \"without success\"}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895ff1267e44ed86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T12:58:11.115065Z",
     "start_time": "2025-05-07T12:58:11.040621Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Display Results: Development of Predictions and Mutant-Selection\"\"\"\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "results_plot = make_subplots(\n",
    "    subplot_titles=f\"Development of Predictions and Mutant-Selection to identify the {n_top} active sequences testing {n_samples} new samples per iteration.\",\n",
    "    rows=1, cols=2)\n",
    "\n",
    "'''First Plot for Results Tracking'''\n",
    "results_plot.append_trace(\n",
    "    go.Scatter(name=\"highest scoring mutant\", x=[result[0] for result in results],\n",
    "               y=[round(float(result[1]), 3) for result in results],\n",
    "               marker=dict(color=\"darkcyan\", size=3),\n",
    "               mode=\"lines\"), row=1, col=1)\n",
    "\n",
    "results_plot.append_trace(\n",
    "    go.Scatter(name=\"average of mutants' score\", x=[result[0] for result in results],\n",
    "               y=[round(float(result[2]), 3) for result in results],\n",
    "               marker=dict(color=\"red\", size=3),\n",
    "               mode=\"lines\"), row=1, col=1)\n",
    "\n",
    "results_plot.append_trace(\n",
    "    go.Scatter(name=\"Standard Deviation of mutant scores\", x=[result[0] for result in results],\n",
    "               y=[round(float(result[3]), 3) for result in results],\n",
    "               marker=dict(color=\"grey\", size=3),\n",
    "               mode=\"lines\"), row=1, col=1)\n",
    "\n",
    "\n",
    "'''Second Plot for Performance Tracking'''\n",
    "results_plot.append_trace(\n",
    "    go.Scatter(name=\"R2 for MLDE Validational Datapoints\", x=[i for i, scores in enumerate(val_performances)],\n",
    "               y=[scores[0] for scores in test_performances],\n",
    "               marker=dict(color=\"lightgreen\", size=3),\n",
    "               mode=\"lines\"), row=1, col=2)\n",
    "\n",
    "results_plot.append_trace(\n",
    "    go.Scatter(name=\"RMSE for MLDE Validational Datapoints\", x=[i for i, scores in enumerate(val_performances)],\n",
    "               y=[scores[1] for scores in test_performances],\n",
    "               marker=dict(color=\"darkmagenta\", size=3),\n",
    "               mode=\"lines\"), row=1, col=2)\n",
    "\n",
    "results_plot.append_trace(\n",
    "    go.Scatter(name=\"R2 for remaining Dataset\", x=[i for i, scores in enumerate(test_performances)],\n",
    "               y=[scores[0] for scores in test_performances],\n",
    "               marker=dict(color=\"darkgreen\", size=3),\n",
    "               mode=\"lines\"), row=1, col=2)\n",
    "\n",
    "results_plot.append_trace(\n",
    "    go.Scatter(name=\"RMSE for remaining Dataset\", x=[i for i, scores in enumerate(test_performances)],\n",
    "               y=[scores[1] for scores in test_performances],\n",
    "               marker=dict(color=\"magenta\", size=3),\n",
    "               mode=\"lines\"), row=1, col=2)\n",
    "#\n",
    "results_plot.update_layout(\n",
    "    title_text=f\"Development of Predictions and Mutant-Selection to identify the {n_top} active sequences testing {n_samples} new samples per iteration with {model_type}-{repr_type} for {data_set_name_shortened}\",\n",
    "    title_font=dict(color=\"black\", size=20),\n",
    "    showlegend=True,\n",
    "    paper_bgcolor='rgb(233,233,233)',\n",
    "    plot_bgcolor='rgb(233,233,233)',\n",
    "    # height=1000,\n",
    "    width=1500,\n",
    "    legend=dict(font=dict(color=\"black\",\n",
    "                          size=12)))\n",
    "#\n",
    "results_plot.update_yaxes(\n",
    "    dict(\n",
    "        title_text=\"Activity-Score\",\n",
    "        title_font=dict(color=\"black\"),\n",
    "        # range=[min_score, max_score],\n",
    "        color='black',\n",
    "        showgrid=True,\n",
    "        gridcolor='grey',\n",
    "        griddash=\"dot\",\n",
    "        gridwidth=0.2),\n",
    "    row=1, col=1)\n",
    "\n",
    "results_plot.update_xaxes(\n",
    "    dict(\n",
    "        title_text=\"cycles\",\n",
    "        title_font=dict(color=\"black\"),\n",
    "        # range=[min_score, max_score],\n",
    "        color='black',\n",
    "        showgrid=True,\n",
    "        gridcolor='grey',\n",
    "        griddash=\"dot\",\n",
    "        gridwidth=0.2),\n",
    "    row=1, col=1)\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"browser\"\n",
    "with HiddenWarnings():\n",
    "    results_plot.show()\n",
    "    results_plot.write_image(f\"MLDE_Development_{data_set_name_shortened}_{repr_type}_{n_samples}-samples.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
